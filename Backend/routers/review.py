import re
from fastapi import APIRouter, UploadFile, File, Form
from fastapi.responses import JSONResponse
from config import client, logger, LANGUAGE_MAP, MAX_CHARS_PER_CHUNK
from utils.chunk import smart_chunking
from utils.common import build_chunk_prompt, extract_refactored_code
from utils.security import allowed_file, file_size_okay
from utils.sast import semgrep_scan_code
from utils.mask_utils import mask_all_sensitive_in_result
from utils.split_utils import split_jsp, split_aspx, split_html
from utils.gpt_sidekick import ask_sidekick

router = APIRouter()

def format_review_output(raw_result: dict) -> str:
    output = []

    # [ì •ì  ë¶„ì„ ê²°ê³¼]
    output.append("ğŸ” [ì •ì  ë¶„ì„ ê²°ê³¼]")
    output.append(raw_result.get("sast_result", "").strip())

    # [ì „ì²´ ìš”ì•½]
    output.append("\nğŸ§© [ì „ì²´ ì½”ë“œ ìš”ì•½]")
    output.append(raw_result.get("summary", "").strip())

    # [ë¦¬ë·° ì„¹ì…˜]
    output.append("\nğŸ§  [ì½”ë“œ ë¦¬ë·°]")
    for review in raw_result.get("reviews", []):
        index = review["chunk_index"] + 1
        markdown = review.get("markdown", "").strip()
        refactor = review.get("refactored_code", "").strip()

        output.append(f"\n--- â¬› Chunk {index} â¬› ---")

        # ë¦¬ë·° ë¶„ì„ ë¸”ë¡
        if "ê¸°ëŠ¥ ì„¤ëª…:" in markdown or "ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„:" in markdown:
            # ì´ë¯¸ êµ¬ë¶„ë¼ ìˆëŠ” ê²½ìš°
            output.append(markdown)
        else:
            output.append("ë¦¬ë·°:\n" + markdown)

        # ë¦¬íŒ©í† ë§ ì½”ë“œ ë³„ë„ êµ¬ë¶„
        if refactor:
            output.append("\në¦¬íŒ©í† ë§ ì½”ë“œ:\n" + refactor)

    # ìµœì¢… í†µí•© ë¦¬íŒ©í† ë§ ì½”ë“œ
    final = raw_result.get("final_refactored", "").strip()
    if final:
        output.append("\nâœ… [ìµœì¢… ë¦¬íŒ©í† ë§ ì½”ë“œ í†µí•©]")
        output.append(final)

    return "\n\n".join(output)



@router.post("/review/")
async def review_code(
    file: UploadFile = File(...),
    model: str = Form("gpt-3.5-turbo")
):
    try:
        if not allowed_file(file.filename):
            return JSONResponse(status_code=400, content={"error": "í—ˆìš©ë˜ì§€ ì•ŠëŠ” í™•ì¥ìì…ë‹ˆë‹¤."})

        content = await file.read()
        if not file_size_okay(content):
            return JSONResponse(status_code=400, content={"error": "íŒŒì¼ ìš©ëŸ‰ì´ ë„ˆë¬´ í½ë‹ˆë‹¤."})
            
        code = content.decode("utf-8")
        ext = file.filename.split('.')[-1].lower()
        language = LANGUAGE_MAP.get(ext, "Plain Text")

        logger.info(f"ì •ì ë¶„ì„ ì‹œì‘ : {file.filename}")

        # JSP/ASPX ë¶„ë¦¬ ë¶„ì„ ë¶„ê¸°
        sast_result = ""
        if ext == "jsp":
            # html, java, js, css ë¶„ë¦¬
            html_part, java_part, js_part, css_part = split_jsp(code)
            sast_html = semgrep_scan_code(html_part, 'html')
            sast_java = semgrep_scan_code(java_part, 'java') if java_part.strip() else "[Java ì½”ë“œ ì—†ìŒ]"
            sast_js = semgrep_scan_code(js_part, 'js') if js_part.strip() else "[JS ì½”ë“œ ì—†ìŒ]"
            sast_css = semgrep_scan_code(css_part, 'css') if css_part.strip() else "[CSS ì½”ë“œ ì—†ìŒ]"
            sast_result = (
                f"[HTML ë¶„ì„]\n{sast_html}\n\n"
                f"[Java ë¶„ì„]\n{sast_java}\n\n"
                f"[JS ë¶„ì„]\n{sast_js}\n\n"
                f"[CSS ë¶„ì„]\n{sast_css}"
            )

        elif ext == "aspx":
            # html, cs, js, css ë¶„ë¦¬
            html_part, cs_part, js_part, css_part = split_aspx(code)
            sast_html = semgrep_scan_code(html_part, 'html')
            sast_cs = semgrep_scan_code(cs_part, 'cs') if cs_part.strip() else "[C# ì½”ë“œ ì—†ìŒ]"
            sast_js = semgrep_scan_code(js_part, 'js') if js_part.strip() else "[JS ì½”ë“œ ì—†ìŒ]"
            sast_css = semgrep_scan_code(css_part, 'css') if css_part.strip() else "[CSS ì½”ë“œ ì—†ìŒ]"
            sast_result = (
                f"[HTML ë¶„ì„]\n{sast_html}\n\n"
                f"[C# ë¶„ì„]\n{sast_cs}\n\n"
                f"[JS ë¶„ì„]\n{sast_js}\n\n"
                f"[CSS ë¶„ì„]\n{sast_css}"
            )
        elif ext in ["java", "js", "html", "py", "cs", "css"]:
            sast_result = semgrep_scan_code(code, ext)
        elif ext == "html":
            html_only, js_code, css_code = split_html(code)
            sast_html = semgrep_scan_code(html_only, 'html')
            sast_js = semgrep_scan_code(js_code, 'js') if js_code.strip() else "[JS ì½”ë“œ ì—†ìŒ]"
            sast_css = semgrep_scan_code(css_code, 'css') if css_code.strip() else "[CSS ì½”ë“œ ì—†ìŒ]"
            sast_result = (
                f"[HTML ë¶„ì„]\n{sast_html}\n\n"
                f"[JS ë¶„ì„]\n{sast_js}\n\n"
                f"[CSS ë¶„ì„]\n{sast_css}"
            )
        else:
            sast_result = "[ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ ìœ í˜•ì´ê±°ë‚˜ SAST ë¶„ì„ ë¶ˆê°€]"

        #print(f"[ì •ì ë¶„ì„(ë¶„ë¦¬ ê²°ê³¼)]\n{sast_result}")
        
        # 1. ì½”ë“œ chunk ë¶„í• 
        chunks = smart_chunking(code, MAX_CHARS_PER_CHUNK, language)
        total = len(chunks)
        
        # 2. ê° chunkë³„ ìš”ì•½
        chunk_summaries = []
        
        for idx, chunk in enumerate(chunks):
            chunk_summary_prompt = f"""
ì•„ë˜ëŠ” ì „ì²´ {language} ì½”ë“œì˜ ì¼ë¶€ì•¼. ì´ ë¶€ë¶„ì˜ êµ¬ì¡°ì™€ ì£¼ìš” ê¸°ëŠ¥ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ì¤˜.

[ì½”ë“œ ì‹œì‘]
{chunk}
[ì½”ë“œ ë]
"""
            logger.info(f"â–¶ Chunk {idx+1}/{total} ìš”ì•½ ìš”ì²­ ì¤‘... ëª¨ë¸: {model}")
            chunk_summary = ask_sidekick(chunk_summary_prompt, model, 0.2)
            chunk_summaries.append(chunk_summary)

        # 3. chunkë³„ ìš”ì•½ìœ¼ë¡œ ì „ì²´ ìš”ì•½ ìƒì„±
        total_summary_prompt = f"""
ì•„ë˜ëŠ” ëŒ€í˜• {language} ì½”ë“œ íŒŒì¼ì„ ì—¬ëŸ¬ ê°œ chunkë¡œ ë‚˜ëˆ ì„œ ê° ë¶€ë¶„ë³„ë¡œ ìš”ì•½í•œ ë‚´ìš©ì´ì•¼.

[ì •ì ë¶„ì„(ë¶„ë¦¬ ê²°ê³¼)]
{sast_result}

ê° chunkë³„ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ì½”ë“œì˜ êµ¬ì¡°ì™€ ê¸°ëŠ¥ì„ í†µí•©ì ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
ì¤‘ë³µ ì—†ì´ ì „ì²´ì ì¸ íë¦„, ì£¼ìš” ì—­í• , í•µì‹¬ êµ¬ì¡° ìœ„ì£¼ë¡œ ì •ë¦¬í•´ì¤˜.

{chr(10).join(chunk_summaries)}
"""
        code_summary = ask_sidekick(total_summary_prompt, model, 0.2)

        # 4. chunkë³„ ì½”ë“œ ë¦¬ë·°/ë¦¬íŒ©í„°
        chunk_reviews = []
        for idx, chunk in enumerate(chunks):
            prompt = build_chunk_prompt(chunk, ext, language, idx, total, code_summary)
            logger.info(f"â–¶ Chunk {idx+1}/{total} ë¦¬ë·° ìš”ì²­ ì¤‘... ëª¨ë¸: {model}")
            
            part_review = ask_sidekick(prompt, model, 0.2)

            chunk_reviews.append({
                "chunk_index": idx,
                "markdown": part_review,
                "refactored_code": extract_refactored_code(part_review)
            })

        final_refactor = "\n".join([r["refactored_code"] for r in chunk_reviews if r["refactored_code"]])

        raw_result = {
            "sast_result": sast_result,
            "summary": code_summary,
            "reviews": chunk_reviews,
            "final_refactored": final_refactor
        }
        
        return raw_result
        #return mask_all_sensitive_in_result(raw_result)

    except Exception as e:
        logger.error(f"[ì—ëŸ¬ ë°œìƒ] {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})
